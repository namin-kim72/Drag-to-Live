# Drag-to-Live: Controllable Cloud Animation on Edge Device

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)](https://pytorch.org/)
[![Diffusers](https://img.shields.io/badge/Diffusers-0.31.0-yellow)](https://huggingface.co/docs/diffusers/index)
[![Gradio](https://img.shields.io/badge/Demo-OpenCV-green)]()

## ğŸ“– Introduction
ìµœì‹  ì˜ìƒ ìƒì„± AI(Sora, Runway ë“±)ëŠ” í€„ë¦¬í‹°ê°€ ë†’ì§€ë§Œ, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” êµ¬ì²´ì ì¸ ì›€ì§ì„ì„ ì œì–´(Control)í•˜ê¸° ì–´ë µë‹¤ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê¸°ì¡´ ì—°êµ¬ì¸ *Wan-Move* ë“±ì€ H100ê¸‰ì˜ ê³ ì„±ëŠ¥ GPUë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤.

**Drag-to-Live**ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ **ê²½ëŸ‰í™” í’ê²½ ì œì–´ ëª¨ë¸**ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê¶¤ì (Trajectory)ì„ ê¸°ë°˜ìœ¼ë¡œ ì •ì§€ëœ ì´ë¯¸ì§€ì— ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ì„ ë¶€ì—¬í•˜ë©°, ìµœì í™”ë¥¼ í†µí•´ **RTX 4060(8GB VRAM) í™˜ê²½ì—ì„œë„ í•™ìŠµ ë° êµ¬ë™**ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

## âœ¨ Key Features
* **ğŸ‘† Intuitive Interface:** ì´ë¯¸ì§€ ìœ„ì— ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì›€ì§ì„ì˜ ë°©í–¥ê³¼ í¬ê¸°ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
* **âš¡ Edge Optimization:** RTX 4060 8GB VRAM í™˜ê²½ì—ì„œë„ í•™ìŠµ ë° ì¶”ë¡ ì´ ê°€ëŠ¥í•˜ë„ë¡ ê²½ëŸ‰í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (Gradient Checkpointing, fp16, 8-frame optimization).
* **ğŸ§  Data-Driven Guidance:** CoTrackerë¡œ ì¶”ì¶œí•œ ë¬¼ë¦¬ì  ê¶¤ì ì„ LoRA(Low-Rank Adaptation)ì— í•™ìŠµì‹œì¼œ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ë¦„ì˜ íë¦„ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
* **ğŸ¥ High Quality:** Stable Diffusion v1.5ì™€ AnimateDiffë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œë„¤ë§ˆí‹±í•œ íƒ€ì„ë©ìŠ¤ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ—ï¸ System Architecture
<img width="4729" height="4465" alt="User Trajectory Cloud-2025-12-18-061955" src="https://github.com/user-attachments/assets/0fc1e0ea-faef-4c38-8c69-5bb860453889" />

ë³¸ í”„ë¡œì íŠ¸ëŠ” CoTracker(Trajectory Encoder)ì™€ **AnimateDiff(Motion Generator)**, ê·¸ë¦¬ê³  LoRA(Style Controller)ì˜ ìœ ê¸°ì ì¸ ê²°í•©ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
1.  **Input:** ì •ì§€ ì´ë¯¸ì§€ + ì‚¬ìš©ì ì…ë ¥ ê¶¤ì 
2.  **Encoding:** CoTrackerê°€ ê¶¤ì ì„ ì¢Œí‘œ ë°ì´í„°ë¡œ ë³€í™˜
3.  **Generation:** AnimateDiffê°€ ì‹œê°„ ì¶•ì„ ìƒì„±í•˜ê³ , í•™ìŠµëœ LoRAê°€ êµ¬ë¦„ì˜ ë¬¼ë¦¬ì  ì›€ì§ì„ì„ ì£¼ì…
4.  **Output:** 8~16 í”„ë ˆì„ì˜ ê³ í™”ì§ˆ íƒ€ì„ë©ìŠ¤ ì˜ìƒ

## ğŸ“¦ Installation

### Prerequisites
* Windows 10/11 or Linux
* NVIDIA GPU (VRAM 8GB ì´ìƒ ê¶Œì¥)
* Python 3.10+
* Anaconda (Recommended)

### Setup
```bash
# 1. Clone the repository
git clone [https://github.com/namin-kim72/Drag-to-Live.git](https://github.com/namin-kim72/Drag-to-Live.git)
cd Drag-to-Live

# 2. Create Conda environment
conda create -n drag2live python=3.10
conda activate drag2live

# 3. Install dependencies
# (CoTracker ì„¤ì¹˜ë¥¼ ìœ„í•´ gitì´ í•„ìš”í•©ë‹ˆë‹¤)
pip install -r requirements.txt
